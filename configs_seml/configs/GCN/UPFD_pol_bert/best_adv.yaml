seml:
  executable: main.py
  output_dir: configs_seml/logs
  project_root_dir: ../../../..
  conda_environment: gtr

slurm:
  experiments_per_job: 1
  sbatch_options:
    partition: gpu_gtx1080
    gres: gpu:1       # num GPUs
    mem: 16G          # memory
    cpus-per-task: 4  # num cores
    time: 1-00:00     # max time, D-HH:MM
    qos: deadline

fixed:
  graphgym:  
    accelerator: cuda
    attack:
      enable: true
      num_attacked_graphs: 30
      skip_incorrect_graph_classification: false
      log_progress: false
      load_best_model: false
      split: test
      prediction_level: graph
      remove_isolated_components: true
      run_random_baseline: true
      block_size: 1_000  # TODO: test
      epochs: 125  # TODO: test
      epochs_resampling: 100
      resample_period: 1  # TODO: test
      max_final_samples: 20  # TODO: test
      eps: 1.0e-07  # TODO: test
      eps_init_noised: false  # TODO: test
      is_undirected: true
      loss: raw_prediction  # TODO: test
      metric: null
      lr: 4000  # TODO: test
      max_edge_weight_update: 0.0  # TODO: test
      max_trials_sampling: 20
      minimum_budget: 1
      node_prob_enable: true
      node_prob_iterations: 3
      node_prob_log: true
      root_node_idx: 0
      with_early_stopping: true
      node_injection:
        enable: true
        from_train: true
        from_val: true
        from_test: true
        allow_existing_graph_pert: false
        sample_only_connected: true
        include_root_nodes: false
        sample_only_trees: true
    benchmark: false
    bn:
      eps: 1.0e-05
      mom: 0.1
    custom_metrics: []
    dataset:
      cache_load: false
      cache_save: false
      dir: ./datasets
      edge_dim: 128
      edge_encoder: false
      edge_encoder_bn: true
      edge_encoder_name: Bond
      edge_encoder_num_types: 0
      edge_message_ratio: 0.8
      edge_negative_sampling_ratio: 1.0
      edge_train_mode: all
      encoder: true
      encoder_bn: true
      encoder_dim: 128
      encoder_name: db
      format: PyG-UPFD
      infer_link_label: null
      label_column: none
      label_table: none
      location: local
      name: politifact-bert
      node_encoder: true
      node_encoder_bn: false
      node_encoder_name: LinearNode
      node_encoder_num_types: 0
      remove_feature: false
      resample_disjoint: false
      resample_negative: false
      shuffle_split: true
      slic_compactness: 10
      split:
      - 0.8
      - 0.1
      - 0.1
      split_dir: ./splits
      split_index: 0
      split_mode: standard
      task: graph
      task_type: classification_binary
      to_undirected: false
      transductive: false
      transform: none
      tu_simple: true
    devices: 1
    example_arg: example
    example_group:
      example_arg: example
    gnn:
      act: relu
      agg: add
      att_final_linear: false
      att_final_linear_bn: false
      att_heads: 1
      batchnorm: true
      clear_feature: true
      dim_inner: 473
      dropout: 0.0
      head: weighted_mean_pool_graph
      keep_edge: 0.5
      l2norm: true
      layer_type: gcnconvweighted
      layers_mp: 2
      layers_post_mp: 3
      layers_pre_mp: 0
      msg_direction: single
      normalize_adj: false
      residual: false
      self_msg: concat
      skip_every: 1
      stage_type: stack
    gpu_mem: false
    mem:
      inplace: false
    metric_agg: argmax
    metric_best: accuracy
    model:
      edge_decoding: dot
      graph_pooling: add
      loss_fun: cross_entropy
      match_upper: true
      size_average: mean
      thresh: 0.5
      type: gnn

    train:
      mode: adversarial
      eval_period: 1
      batch_size: 16
      adv:
        batched_train: False
        e_budget: 0.15
        block_size: 500
        num_replays: 5
        lr: 5000
        # for val
        e_budget_val: 0.1
        block_size_val: 1000
        epochs_val: 12
        lr_val: 4000
  
    optim:
      base_lr: 0.005286030166148311
      batch_accumulation: 1
      clip_grad_norm: true
      clip_grad_norm_value: 5.0
      early_stopping: true
      early_stopping_delta_e: 0.04
      early_stopping_patience: 6
      early_stopping_warmup: 6
      lr_decay: 0.1
      max_epoch: 60
      min_lr: 0.0
      momentum: 0.9
      num_warmup_epochs: 10
      optimizer: adamW
      reduce_factor: 0.1
      schedule_patience: 10
      scheduler: cosine_with_warmup
      steps:
      - 30
      - 60
      - 90
      weight_decay: 0.025931832281559417
    seed: 1094
