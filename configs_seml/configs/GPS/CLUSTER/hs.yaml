seml:
  executable: main.py
  output_dir: configs_seml/logs
  project_root_dir: ../../../..
  conda_environment: gtr

slurm:
  experiments_per_job: 2
  sbatch_options:
    partition: gpu_gtx1080
    gres: gpu:1       # num GPUs
    mem: 32G          # memory
    cpus-per-task: 4  # num cores
    time: 1-00:00     # max time, D-HH:MM

# Hyperparameter search

random:
  samples: 10
  seed: 187

  graphgym.seed:
    seed: 786
    type: randint
    min: 0
    max: 10000

  graphgym.optim.base_lr:
    seed: 2264
    type: loguniform
    min: 3.0e-5
    max: 1.0e-2

  graphgym.optim.weight_decay:
    seed: 89
    type: loguniform
    min: 1.0e-8
    max: 1.0e-3

  graphgym.gt.n_heads:
    seed: 13094
    type: choice
    options:
      - 6
      - 8

  dims_per_head:
    seed: 164
    type: randint
    min: 3
    max: 9

  graphgym.gt.layers:
    seed: 357
    type: randint
    min: 2
    max: 13

  graphgym.posenc_WLapPE.eigen.max_freqs:
    seed: 392
    type: randint
    min: 5
    max: 30

  graphgym.posenc_WLapPE.layers:
    seed: 7154
    type: choice
    options:
      - 1
      - 2
      - 3

  graphgym.gnn.layers_post_mp:
    seed: 96624
    type: choice
    options:
      - 1
      - 2


# experiment fixed configs

fixed:

  graphgym:

    accelerator: cuda
    out_dir: configs_seml/results
    metric_best: accuracy-SBM
    metric_agg: argmax
    tensorboard_each_run: false

    dataset:
      format: PyG-GNNBenchmarkDataset
      name: CLUSTER
      task: graph
      task_type: classification
      transductive: false
      split_mode: standard
      node_encoder: true
      node_encoder_name: WLapPE
      node_encoder_bn: false

    train:
      mode: custom
      eval_period: 1
      batch_size: 16

    model:
      type: GPSModel
      loss_fun: weighted_cross_entropy

    posenc_WLapPE:
      enable: true
      dim_pe: 16
      model: DeepSet
      eigen:
        eigvec_norm: L2
        laplacian_norm: sym
      pass_as_var: false
      post_layers: 0
      raw_norm_type: none

    gt:
      layer_type: WeightedGCN+Transformer
      dim_hidden: 0  # determined using num_heads and dims_per_head
      layer_norm: false
      batch_norm: true
      dropout: 0.1
      attn_dropout: 0.5

    gnn:
      batchnorm: true
      act: relu
      head: inductive_node
      layers_pre_mp: 0
      dim_inner: 0  # determined using num_heads and dims_per_head

    optim:
      clip_grad_norm: true
      clip_grad_norm_value: 5.0
      optimizer: adamW
      max_epoch: 100
      scheduler: cosine_with_warmup
      num_warmup_epochs: 5
      early_stopping: true
      early_stopping_patience: 30
      early_stopping_delta_e: 0.02
      early_stopping_warmup: 30

    attack:
      enable: false
